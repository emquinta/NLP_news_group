{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this challenge, I applied Bag of Words and Tfidf to the 20 newsgroup dataset that is made available through the scikit learn dataset package."
      ],
      "metadata": {
        "id": "7_a2fhadYdah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true,
        "id": "TbyhGYQUyC_c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import sklearn\n",
        "from sklearn import metrics    \n",
        "import timeit\n",
        "import spacy\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset_full = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
        "newsdf = pd.DataFrame()\n",
        "newsdf['text'] = dataset_full.data\n",
        "newsdf['source'] = dataset_full.target\n",
        "label=[]\n",
        "for i in newsdf['source']:\n",
        "    label.append(dataset_full.target_names[i])\n",
        "newsdf['label']=label\n",
        "\n",
        "dataset_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
        "newsdf_train = pd.DataFrame()\n",
        "newsdf_train['text'] = dataset_train.data\n",
        "newsdf_train['source'] = dataset_train.target\n",
        "label=[]\n",
        "for i in newsdf_train['source']:\n",
        "    label.append(dataset_train.target_names[i])\n",
        "newsdf_train['label']=label\n",
        "\n",
        "dataset_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True, random_state=42)\n",
        "newsdf_test = pd.DataFrame()\n",
        "newsdf_test['text'] = dataset_test.data\n",
        "newsdf_test['source'] = dataset_test.target\n",
        "label=[]\n",
        "for i in newsdf_test['source']:\n",
        "    label.append(dataset_test.target_names[i])\n",
        "newsdf_test['label']=label"
      ],
      "metadata": {
        "id": "D3p2gbnLyOJy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wjcZVjR_yWnw",
        "outputId": "5be6c53a-48dc-4dd3-a8b7-1c74976eb97a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-32bb432e-34b6-49b8-b884-f2166e4993bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My brother is in the market for a high-perform...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
              "      <td>17</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32bb432e-34b6-49b8-b884-f2166e4993bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32bb432e-34b6-49b8-b884-f2166e4993bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32bb432e-34b6-49b8-b884-f2166e4993bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...                     label\n",
              "0  \\n\\nI am sure some bashers of Pens fans are pr...  ...          rec.sport.hockey\n",
              "1  My brother is in the market for a high-perform...  ...  comp.sys.ibm.pc.hardware\n",
              "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...  ...     talk.politics.mideast\n",
              "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...  ...  comp.sys.ibm.pc.hardware\n",
              "4  1)    I have an old Jasmine drive which I cann...  ...     comp.sys.mac.hardware\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import metrics    \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import timeit\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from nltk.corpus import gutenberg, stopwords\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iag0uuRZHB4w",
        "outputId": "62f360ba-1a0d-455e-d659-da8538ec3fb9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " nltk.download('stopwords')\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "def textcleaner_stem(text):\n",
        "    ''' Takes in raw unformatted text and strips punctuation, removes whitespace,\n",
        "    strips numbers, tokenizes and stems.\n",
        "    Returns string of processed text to be used into CountVectorizer\n",
        "    '''\n",
        "    # Lowercase and strip everything except words\n",
        "    cleaner = re.sub(r\"[^a-zA-Z ]+\", ' ', text.lower())\n",
        "    # Tokenize\n",
        "    cleaner = word_tokenize(cleaner)\n",
        "    ps = PorterStemmer()\n",
        "    clean = []\n",
        "    for w in cleaner:\n",
        "        # filter out stopwords\n",
        "        if w not in stopWords:\n",
        "            # filter out short words\n",
        "            if len(w)>2:\n",
        "                # Stem \n",
        "                clean.append(ps.stem(w))\n",
        "    return ' '.join(clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDx8IHdYFu9G",
        "outputId": "70161954-7c4d-4227-ef4e-080408bc1b0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newsdf['clean_text_stem'] = newsdf.text.apply(lambda x: textcleaner_stem(x))\n",
        "newsdf_train['clean_text_stem'] = newsdf_train.text.apply(lambda x: textcleaner_stem(x))\n",
        "newsdf_test['clean_text_stem'] = newsdf_test.text.apply(lambda x: textcleaner_stem(x))"
      ],
      "metadata": {
        "id": "JoLSWX3RGeXh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cvz7D_uwyipR",
        "outputId": "858c1221-14b3-481a-ab71-b250ea0cdb8f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c24bf543-dfc0-48a3-8abd-02427fb09527\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>source</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text_stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>sure basher pen fan pretti confus lack kind po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My brother is in the market for a high-perform...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>brother market high perform video card support...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
              "      <td>17</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "      <td>final said dream mediterranean new area greate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
              "      <td>3</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>old jasmin drive use new system understand ups...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c24bf543-dfc0-48a3-8abd-02427fb09527')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c24bf543-dfc0-48a3-8abd-02427fb09527 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c24bf543-dfc0-48a3-8abd-02427fb09527');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...                                    clean_text_stem\n",
              "0  \\n\\nI am sure some bashers of Pens fans are pr...  ...  sure basher pen fan pretti confus lack kind po...\n",
              "1  My brother is in the market for a high-perform...  ...  brother market high perform video card support...\n",
              "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...  ...  final said dream mediterranean new area greate...\n",
              "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...  ...  think scsi card dma transfer disk scsi card dm...\n",
              "4  1)    I have an old Jasmine drive which I cann...  ...  old jasmin drive use new system understand ups...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "def textcleaner_lemmas(text):\n",
        "    ''' Takes in raw unformatted text and strips punctuation, removes whitespace,\n",
        "    strips numbers, tokenizes and stems.\n",
        "    Returns string of processed text to be used into CountVectorizer\n",
        "    '''\n",
        "    # Lowercase and strip everything except words\n",
        "    cleaner = re.sub(r\"[^a-zA-Z ]+\", ' ', text.lower())\n",
        "    # Tokenize\n",
        "    cleaner = word_tokenize(cleaner)\n",
        "    ps = PorterStemmer()\n",
        "    clean = []\n",
        "    for w in cleaner:\n",
        "        # filter out stopwords\n",
        "        if w not in stopWords:\n",
        "            # filter out short words\n",
        "            if len(w)>2:\n",
        "                # lemmatizer \n",
        "                clean.append(lemmatizer.lemmatize(w))\n",
        "    return ' '.join(clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l-ANFigOTdt",
        "outputId": "bc3ae94d-2cd9-477c-db39-44b0610573bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "trusted": true,
        "id": "FAWZ9CVryC_j"
      },
      "outputs": [],
      "source": [
        "newsdf['clean_text_lemma'] = newsdf.text.apply(lambda x: textcleaner_lemmas(x))\n",
        "newsdf_train['clean_text_lemma'] = newsdf_train.text.apply(lambda x: textcleaner_lemmas(x))\n",
        "newsdf_test['clean_text_lemma'] = newsdf_test.text.apply(lambda x: textcleaner_lemmas(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "BOWvectorizer = CountVectorizer(analyzer='word')\n",
        "\n",
        "x_train_stem = BOWvectorizer.fit_transform(newsdf_train['clean_text_stem'])\n",
        "y_train_stem = newsdf_train['source']\n",
        "x_test_stem = BOWvectorizer.transform(newsdf_test['clean_text_stem'])\n",
        "y_test_stem = newsdf_test['source']\n",
        "features_train = BOWvectorizer.get_feature_names()\n",
        "len(features_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6gaQ6C8P_-p",
        "outputId": "ec49037f-9f66-4094-b4ad-d691d46a2586"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55161"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BOWvectorizer = CountVectorizer(analyzer='word')\n",
        "\n",
        "x_train_lemma = BOWvectorizer.fit_transform(newsdf_train['clean_text_lemma'])\n",
        "y_train_lemma = newsdf_train['source']\n",
        "x_test_lemma = BOWvectorizer.transform(newsdf_test['clean_text_lemma'])\n",
        "y_test_lemma = newsdf_test['source']\n",
        "features_train = BOWvectorizer.get_feature_names()\n",
        "len(features_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD1vv0LeQ5dV",
        "outputId": "af1d2e5a-e87b-4a78-8ce4-77c411c57343"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66613"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train =  x_train_lemma\n",
        "y_train = y_train_lemma\n",
        "X_test = x_test_lemma \n",
        "y_test = y_test_lemma"
      ],
      "metadata": {
        "id": "4x6DTb2CST90"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "# Models\n",
        "lr = LogisticRegression()\n",
        "rfc = RandomForestClassifier()\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "rfc.fit(X_train, y_train)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbc.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbc.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkpL7YSXSaem",
        "outputId": "be49f068-47cc-419d-f7c5-60445fba1aeb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9700371221495492\n",
            "\n",
            "Test set score: 0.6141795007966012\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9737493371044723\n",
            "\n",
            "Test set score: 0.6123207647371216\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.8604383949089623\n",
            "\n",
            "Test set score: 0.6066117896972916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "Tfidfvectorizer = TfidfVectorizer(\n",
        "    max_df=0.5, min_df=2, use_idf=True, norm=u'l2', smooth_idf=True)\n",
        "\n",
        "x_train_tfidf = Tfidfvectorizer.fit_transform(newsdf_train['clean_text_lemma'])\n",
        "y_train_tfidf = newsdf_train['source']\n",
        "x_test_tfidf = Tfidfvectorizer.transform(newsdf_test['clean_text_lemma'])\n",
        "y_test_tfidf = newsdf_test['source']\n",
        "features_train = Tfidfvectorizer.get_feature_names()\n",
        "len(features_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9g-NpbgS0Hh",
        "outputId": "c505059d-b550-41fa-8b5e-49c3390ca7c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29942"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train =  x_train_tfidf\n",
        "Y_train = y_train_tfidf\n",
        "X_test = x_test_tfidf \n",
        "Y_test = y_test_tfidf"
      ],
      "metadata": {
        "id": "HmHZyixKTL-x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrtfidf = LogisticRegression()\n",
        "rfctfidf = RandomForestClassifier()\n",
        "gbctfidf = GradientBoostingClassifier()\n",
        "\n",
        "lrtfidf.fit(X_train, y_train)\n",
        "rfctfidf.fit(X_train, y_train)\n",
        "gbctfidf.fit(X_train, y_train)\n",
        "\n",
        "print(\"----------------------Logistic Regression Scores----------------------\")\n",
        "print('Training set score:', lrtfidf.score(X_train, y_train))\n",
        "print('\\nTest set score:', lrtfidf.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Random Forest Scores----------------------\")\n",
        "print('Training set score:', rfctfidf.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfctfidf.score(X_test, y_test))\n",
        "\n",
        "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
        "print('Training set score:', gbctfidf.score(X_train, y_train))\n",
        "print('\\nTest set score:', gbctfidf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWEDYPPqTmHW",
        "outputId": "6b3481a7-ca1a-45c3-914d-b8f8416d628c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------Logistic Regression Scores----------------------\n",
            "Training set score: 0.9025985504684462\n",
            "\n",
            "Test set score: 0.6833510355815189\n",
            "----------------------Random Forest Scores----------------------\n",
            "Training set score: 0.9733074067526958\n",
            "\n",
            "Test set score: 0.611125862984599\n",
            "----------------------Gradient Boosting Scores----------------------\n",
            "Training set score: 0.9117023157150433\n",
            "\n",
            "Test set score: 0.5950610727562401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neither one of the models seemed to predict the news topic very well, but it looks like the Tfidf model had training and test scores that were a little closer together so it may have reduced the overfitting problem.\n",
        "\n",
        "I am not exactly sure why the models didn't work as well. In the program, we focused on distinguishing between two authors. Maybe it's possible that since there are 20 different news topics in this data set, the multiple classification task is too much for the models I generated."
      ],
      "metadata": {
        "id": "KyrsuZLRXFrm"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "nlp-news-group challenge.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}